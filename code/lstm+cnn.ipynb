{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d274a583",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import nltk\n",
    "from nltk.tokenize import sent_tokenize\n",
    "from sklearn.metrics.pairwise import cosine_similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7e8c223e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-18 17:33:32.868204: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer,AutoModel\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9cbf5e62",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "def read_squad(path):\n",
    "    with open(path, 'rb') as f:\n",
    "        squad_dict = json.load(f)\n",
    "    contexts = []\n",
    "    questions = []\n",
    "    answers = []\n",
    "\n",
    "    for group in squad_dict['data']:\n",
    "        for passage in group['paragraphs']:\n",
    "            context = passage['context']\n",
    "            for qa in passage['qas']:\n",
    "                question = qa['question']\n",
    "\n",
    "                if 'plausible_answers' in qa.keys():\n",
    "                    access = 'plausible_answers'\n",
    "                else:\n",
    "                    access = 'answers'\n",
    "                for answer in qa[access]:\n",
    "\n",
    "                    contexts.append(context)\n",
    "                    questions.append(question)\n",
    "                    answers.append(answer)\n",
    "    return contexts, questions, answers\n",
    "\n",
    "\n",
    "train_contexts, train_questions, train_answers = read_squad('squad/train-v2.0.json')\n",
    "val_contexts, val_questions, val_answers = read_squad('squad/dev-v2.0.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d69232dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from gensim.models import Word2Vec\n",
    "np.random.seed(42)\n",
    "train_contexts = np.array(train_contexts)\n",
    "train_questions = np.array(train_questions)\n",
    "train_answers = np.array(train_answers)\n",
    "\n",
    "val_contexts = np.array(val_contexts)\n",
    "val_questions = np.array(val_questions)\n",
    "val_answers = np.array(val_answers)\n",
    "\n",
    "train_indices = np.random.choice(len(train_contexts), 5000, replace=False)\n",
    "val_indices = np.random.choice(len(val_contexts), 500, replace=False)\n",
    "\n",
    "train_contexts_sampled = train_contexts[train_indices]\n",
    "train_questions_sampled = train_questions[train_indices]\n",
    "train_answers_sampled = train_answers[train_indices]\n",
    "\n",
    "val_contexts_sampled = val_contexts[val_indices]\n",
    "val_questions_sampled = val_questions[val_indices]\n",
    "val_answers_sampled = val_answers[val_indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6b353d33",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_contexts_sampled = train_contexts_sampled.tolist()\n",
    "train_questions_sampled = train_questions_sampled.tolist()\n",
    "train_answers_sampled =train_answers_sampled.tolist()\n",
    "\n",
    "val_contexts_sampled = val_contexts_sampled.tolist()\n",
    "val_questions_sampled = val_questions_sampled.tolist()\n",
    "val_answers_sampled = val_answers_sampled.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "de61cc34",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_end_idx(answers, contexts):\n",
    "    for answer, context in zip(answers, contexts):\n",
    "        gold_text = answer['text']\n",
    "        start_idx = answer['answer_start']\n",
    "        end_idx = start_idx + len(gold_text)\n",
    "\n",
    "        if context[start_idx:end_idx] == gold_text:\n",
    "            answer['answer_end'] = end_idx\n",
    "        else:\n",
    "            for n in [1, 2]:\n",
    "                if context[start_idx-n:end_idx-n] == gold_text:\n",
    "                    answer['answer_start'] = start_idx - n\n",
    "                    answer['answer_end'] = end_idx - n\n",
    "\n",
    "add_end_idx(train_answers_sampled, train_contexts_sampled)\n",
    "add_end_idx(val_answers_sampled, val_contexts_sampled)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "94c7a5e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     /home/kunuruabhishek/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('punkt')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "54ab3099",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /home/kunuruabhishek/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "from nltk.corpus import stopwords\n",
    "stop_words = stopwords.words('english')\n",
    "from nltk.stem import SnowballStemmer\n",
    "stemmer = SnowballStemmer('english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "248ed4b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import regex as re\n",
    "text_cleaning_re = \"@\\S+|https?:\\S+|http?:\\S|[^A-Za-z0-9]+\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1d3e9372",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(text, stem=True):\n",
    "  text = re.sub(text_cleaning_re, ' ', str(text).lower()).strip()\n",
    "  tokens = []\n",
    "  for token in text.split():\n",
    "    if token not in stop_words:\n",
    "      if stem:\n",
    "        tokens.append(stemmer.stem(token))\n",
    "      else:\n",
    "        tokens.append(token)\n",
    "  return \" \".join(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "be1a1f0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Input,Dropout\n",
    "from tensorflow.keras.layers import Embedding, Conv1D, MaxPooling1D, Bidirectional, LSTM, Dense\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.random import set_seed\n",
    "from tqdm import tqdm\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from nltk.tokenize import sent_tokenize\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "cf4661d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.initializers import Constant\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from tensorflow.random import set_seed\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8fc71914",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_pretrained_embeddings(vocSize, embedding_dim, glove_file_path, word_index):\n",
    "    embeddings_index = {}\n",
    "    with open(glove_file_path, encoding='utf-8') as f:\n",
    "        for line in f:\n",
    "            values = line.split()\n",
    "            word = values[0]\n",
    "            coefs = np.asarray(values[1:], dtype='float32')\n",
    "            embeddings_index[word] = coefs\n",
    "\n",
    "    embedding_matrix = np.zeros((vocSize, embedding_dim))\n",
    "    for word, i in word_index.items():\n",
    "        if i < vocSize:\n",
    "            embedding_vector = embeddings_index.get(word)\n",
    "            if embedding_vector is not None:\n",
    "                embedding_matrix[i] = embedding_vector\n",
    "    return embedding_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "745e911e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def CNN_BiDirLSTM(vocab_size, word_index,embedding_dim,glove_file_path):\n",
    "\n",
    "\n",
    "    embedding_matrix = load_pretrained_embeddings(vocab_size, embedding_dim, glove_file_path, word_index)\n",
    "    model = Sequential()\n",
    "    model.add(Embedding(input_dim=vocab_size, output_dim=embedding_dim, embeddings_initializer=Constant(embedding_matrix), input_length=100))\n",
    "    model.add(Conv1D(filters=32, kernel_size=8, activation='relu'))\n",
    "    model.add(MaxPooling1D(pool_size=4))\n",
    "    model.add(Bidirectional(LSTM(64, return_sequences=False)))\n",
    "    model.add(Dense(32, activation='relu'))\n",
    "\n",
    "    model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0f4225d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_texts(texts, tokenizer, max_sequence_length):\n",
    "    texts = [preprocess(text) for text in texts]\n",
    "    sequences = tokenizer.texts_to_sequences(texts)\n",
    "    padded_sequences = pad_sequences(sequences, maxlen=max_sequence_length, padding='post')\n",
    "    return padded_sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2ae4638d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_similarity_scores(context_sentences, question, max_sequence_length, model, tokenizer):\n",
    "    context_sequences = preprocess_texts(context_sentences, tokenizer, 64)\n",
    "    question_sequence = preprocess_texts([question], tokenizer, 64)\n",
    "\n",
    "    all_sequences = np.vstack([context_sequences, question_sequence])\n",
    "    cnn_lstm_embeddings = model.predict(all_sequences)\n",
    "    question_vector = cnn_lstm_embeddings[-1].reshape(1, -1)\n",
    "    context_vectors = cnn_lstm_embeddings[:-1]\n",
    "\n",
    "    similarity_scores = cosine_similarity(context_vectors, question_vector).flatten()\n",
    "    return similarity_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec3a0dad",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0fe088f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_context_by_similarity(context_sentences, similarity_scores, threshold):\n",
    "    filtered_indices = np.where(similarity_scores > threshold)[0]\n",
    "    if len(filtered_indices) == 0:\n",
    "        return ' '.join(context_sentences)\n",
    "    filtered_sentences = [context_sentences[i] for i in filtered_indices]\n",
    "    return ' '.join(filtered_sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "0effee64",
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_squad_contexts(contexts, questions, glove_file_path, threshold=0.5, max_sequence_length=64):\n",
    "    all_sentences = [sent for context in contexts for sent in sent_tokenize(context)]\n",
    "    tokenizer = Tokenizer()\n",
    "    tokenizer.fit_on_texts(all_sentences + questions)\n",
    "    vocab_size = len(tokenizer.word_index) + 1\n",
    "\n",
    "    model = CNN_BiDirLSTM(vocab_size,tokenizer.word_index,100,glove_file_path)\n",
    "\n",
    "    filtered_contexts = []\n",
    "    for context, question in tqdm(zip(contexts, questions), total=len(contexts)):\n",
    "        context_sentences = sent_tokenize(context)\n",
    "        similarity_scores = calculate_similarity_scores(context_sentences, question, max_sequence_length, model, tokenizer)\n",
    "        filtered_context = filter_context_by_similarity(context_sentences, similarity_scores, threshold)\n",
    "        filtered_contexts.append(filtered_context)\n",
    "    return filtered_contexts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "19963a12",
   "metadata": {},
   "outputs": [],
   "source": [
    "glove_file_path = 'glove.6B.100d.txt'\n",
    "\n",
    "# def filter_squad_contexts(contexts, questions):\n",
    "#     filtered_contexts = []\n",
    "#     for context, question in tqdm(zip(contexts, questions), total=len(contexts)):\n",
    "#         context_sentences = context.split('.')  # Split into sentences based on full stops\n",
    "#         preprocessed_sentences = [preprocess(sentence) for sentence in context_sentences]\n",
    "#         preprocessed_question = preprocess(question)\n",
    "#         similarity_scores = calculate_similarity_scores(preprocessed_sentences, preprocessed_question)\n",
    "#         filtered_context = filter_context_by_similarity(context_sentences, similarity_scores, 0.85)\n",
    "#         filtered_contexts.append(filtered_context)\n",
    "#     return filtered_contexts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "fae80496",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-18 17:33:54.031848: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set\n",
      "2024-06-18 17:33:54.032010: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcuda.so.1\n",
      "2024-06-18 17:33:54.307213: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2024-06-18 17:33:54.307745: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: \n",
      "pciBusID: 0000:0a:00.0 name: NVIDIA GeForce GTX 1080 Ti computeCapability: 6.1\n",
      "coreClock: 1.582GHz coreCount: 28 deviceMemorySize: 10.92GiB deviceMemoryBandwidth: 451.17GiB/s\n",
      "2024-06-18 17:33:54.307816: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2024-06-18 17:33:54.308735: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 1 with properties: \n",
      "pciBusID: 0000:41:00.0 name: NVIDIA GeForce GTX 1080 Ti computeCapability: 6.1\n",
      "coreClock: 1.582GHz coreCount: 28 deviceMemorySize: 10.92GiB deviceMemoryBandwidth: 451.17GiB/s\n",
      "2024-06-18 17:33:54.308796: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2024-06-18 17:33:54.309561: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 2 with properties: \n",
      "pciBusID: 0000:42:00.0 name: NVIDIA GeForce GTX 1080 Ti computeCapability: 6.1\n",
      "coreClock: 1.582GHz coreCount: 28 deviceMemorySize: 10.91GiB deviceMemoryBandwidth: 451.17GiB/s\n",
      "2024-06-18 17:33:54.309588: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0\n",
      "2024-06-18 17:33:54.309631: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.11\n",
      "2024-06-18 17:33:54.309655: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.11\n",
      "2024-06-18 17:33:54.310374: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10\n",
      "2024-06-18 17:33:54.310569: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10\n",
      "2024-06-18 17:33:54.310625: W tensorflow/stream_executor/platform/default/dso_loader.cc:60] Could not load dynamic library 'libcusolver.so.10'; dlerror: libcusolver.so.10: cannot open shared object file: No such file or directory\n",
      "2024-06-18 17:33:54.311099: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.11\n",
      "2024-06-18 17:33:54.311137: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.8\n",
      "2024-06-18 17:33:54.311144: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1757] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n",
      "2024-06-18 17:33:54.311517: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-06-18 17:33:54.313057: I tensorflow/compiler/jit/xla_gpu_device.cc:99] Not creating XLA devices, tf_xla_enable_xla_devices not set\n",
      "2024-06-18 17:33:54.313080: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1261] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
      "2024-06-18 17:33:54.313085: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1267]      \n",
      "  0%|          | 0/5000 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Model was constructed with shape (None, 100) for input KerasTensor(type_spec=TensorSpec(shape=(None, 100), dtype=tf.float32, name='embedding_input'), name='embedding_input', description=\"created by layer 'embedding_input'\"), but it was called on an input with incompatible shape (None, 64).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-18 17:33:54.670794: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:116] None of the MLIR optimization passes are enabled (registered 2)\n",
      "2024-06-18 17:33:54.687645: I tensorflow/core/platform/profile_utils/cpu_utils.cc:112] CPU Frequency: 3393250000 Hz\n",
      "100%|██████████| 5000/5000 [02:28<00:00, 33.69it/s]\n",
      "  0%|          | 0/500 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Model was constructed with shape (None, 100) for input KerasTensor(type_spec=TensorSpec(shape=(None, 100), dtype=tf.float32, name='embedding_1_input'), name='embedding_1_input', description=\"created by layer 'embedding_1_input'\"), but it was called on an input with incompatible shape (None, 64).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 500/500 [00:15<00:00, 32.64it/s]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "filtered_train_contexts = filter_squad_contexts(train_contexts_sampled, train_questions_sampled,glove_file_path)\n",
    "filtered_val_contexts = filter_squad_contexts(val_contexts_sampled, val_questions_sampled,glove_file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "42786e8e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipped 11 examples where the answer could not be found in the truncated context.\n"
     ]
    }
   ],
   "source": [
    "def align_answers_with_context(original_contexts, updated_contexts, answers):\n",
    "    new_contexts = []\n",
    "    aligned_answers = []\n",
    "    skipped_count = 0\n",
    "\n",
    "    for orig_context, updated_context, answer in zip(original_contexts, updated_contexts, answers):\n",
    "        start_pos = answer['answer_start']\n",
    "        end_pos = answer['answer_end']\n",
    "        orig_answer = orig_context[start_pos:end_pos]\n",
    "        start_idx = updated_context.find(orig_answer)\n",
    "\n",
    "        if start_idx == -1:\n",
    "            skipped_count += 1\n",
    "\n",
    "            modified_answer = answer.copy()\n",
    "            modified_answer['answer_start'] = len(updated_contexts)\n",
    "            modified_answer['answer_end'] = len(updated_contexts)\n",
    "        else:\n",
    "            new_start_pos = start_idx\n",
    "            new_end_pos = start_idx + len(orig_answer)\n",
    "            # Create a copy of answer and update positions\n",
    "            modified_answer = answer.copy()\n",
    "            modified_answer['answer_start'] = new_start_pos\n",
    "            modified_answer['answer_end'] = new_end_pos\n",
    "\n",
    "        aligned_answers.append(modified_answer)\n",
    "        new_contexts.append(updated_context)\n",
    "\n",
    "    return new_contexts, aligned_answers, skipped_count\n",
    "\n",
    "filtered_train_contexts, train_answers_sampled, skipped_count = align_answers_with_context(train_contexts_sampled, filtered_train_contexts, train_answers_sampled)\n",
    "print(f'Skipped {skipped_count} examples where the answer could not be found in the truncated context.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "7f94e505",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipped 11 examples (0.22%) where the answer could not be found in the truncated context.\n"
     ]
    }
   ],
   "source": [
    "total_contexts = len(train_contexts_sampled) \n",
    "\n",
    "skipped_percentage = (skipped_count / total_contexts) * 100\n",
    "print(f'Skipped {skipped_count} examples ({skipped_percentage:.2f}%) where the answer could not be found in the truncated context.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "9a62a795",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"The first Sky television rights agreement was worth £304 million over five seasons. The next contract, negotiated to start from the 1997–98 season, rose to £670 million over four seasons. The third contract was a £1.024 billion deal with BSkyB for the three seasons from 2001–02 to 2003–04. The league brought in £320 million from the sale of its international rights for the three-year period from 2004–05 to 2006–07. It sold the rights itself on a territory-by-territory basis. Sky's monopoly was broken from August 2006 when Setanta Sports was awarded rights to show two out of the six packages of matches available. This occurred following an insistence by the European Commission that exclusive rights should not be sold to one television company. Sky and Setanta paid a total of £1.7 billion, a two-thirds increase which took many commentators by surprise as it had been widely assumed that the value of the rights had levelled off following many years of rapid growth. Setanta also hold rights to a live 3 pm match solely for Irish viewers. The BBC has retained the rights to show highlights for the same three seasons (on Match of the Day) for £171.6 million, a 63 per cent increase on the £105 million it paid for the previous three-year period. Sky and BT have agreed to jointly pay £84.3 million for delayed television rights to 242 games (that is the right to broadcast them in full on television and over the internet) in most cases for a period of 50 hours after 10 pm on matchday. Overseas television rights fetched £625 million, nearly double the previous contract. The total raised from these deals is more than £2.7 billion, giving Premier League clubs an average media income from league games of around £40 million-a-year from 2007 to 2010.\""
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filtered_train_contexts[12]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "ae83a071",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"The first Sky television rights agreement was worth £304 million over five seasons. The next contract, negotiated to start from the 1997–98 season, rose to £670 million over four seasons. The third contract was a £1.024 billion deal with BSkyB for the three seasons from 2001–02 to 2003–04. The league brought in £320 million from the sale of its international rights for the three-year period from 2004–05 to 2006–07. It sold the rights itself on a territory-by-territory basis. Sky's monopoly was broken from August 2006 when Setanta Sports was awarded rights to show two out of the six packages of matches available. This occurred following an insistence by the European Commission that exclusive rights should not be sold to one television company. Sky and Setanta paid a total of £1.7 billion, a two-thirds increase which took many commentators by surprise as it had been widely assumed that the value of the rights had levelled off following many years of rapid growth. Setanta also hold rights to a live 3 pm match solely for Irish viewers. The BBC has retained the rights to show highlights for the same three seasons (on Match of the Day) for £171.6 million, a 63 per cent increase on the £105 million it paid for the previous three-year period. Sky and BT have agreed to jointly pay £84.3 million for delayed television rights to 242 games (that is the right to broadcast them in full on television and over the internet) in most cases for a period of 50 hours after 10 pm on matchday. Overseas television rights fetched £625 million, nearly double the previous contract. The total raised from these deals is more than £2.7 billion, giving Premier League clubs an average media income from league games of around £40 million-a-year from 2007 to 2010.\""
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_contexts[train_indices[12]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "918674f6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'How much many did the Premier League make from selling its internation rights during 2004-07?'"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_questions_sampled[12]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "eaca92ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "context_sentences=train_contexts[train_indices[12]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "406c0299",
   "metadata": {},
   "outputs": [],
   "source": [
    "question=train_questions_sampled[12]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "d1d8270d",
   "metadata": {},
   "outputs": [],
   "source": [
    "context_sentences = context_sentences.split('.')  # Split into sentences based on full stops\n",
    "preprocessed_sentences = [preprocess(sentence) for sentence in context_sentences]\n",
    "preprocessed_question = preprocess(question)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "8870af58",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['first sky televis right agreement worth 304 million five season',\n",
       " 'next contract negoti start 1997 98 season rose 670 million four season',\n",
       " 'third contract 1',\n",
       " '024 billion deal bskyb three season 2001 02 2003 04',\n",
       " 'leagu brought 320 million sale intern right three year period 2004 05 2006 07',\n",
       " 'sold right territori territori basi',\n",
       " 'sky monopoli broken august 2006 setanta sport award right show two six packag match avail',\n",
       " 'occur follow insist european commiss exclus right sold one televis compani',\n",
       " 'sky setanta paid total 1',\n",
       " '7 billion two third increas took mani comment surpris wide assum valu right level follow mani year rapid growth',\n",
       " 'setanta also hold right live 3 pm match sole irish viewer',\n",
       " 'bbc retain right show highlight three season match day 171',\n",
       " '6 million 63 per cent increas 105 million paid previous three year period',\n",
       " 'sky bt agre joint pay 84',\n",
       " '3 million delay televis right 242 game right broadcast full televis internet case period 50 hour 10 pm matchday',\n",
       " 'oversea televis right fetch 625 million near doubl previous contract',\n",
       " 'total rais deal 2',\n",
       " '7 billion give premier leagu club averag media incom leagu game around 40 million year 2007 2010',\n",
       " '']"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preprocessed_sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "f3410d6e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'much mani premier leagu make sell intern right 2004 07'"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preprocessed_question"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d0ecc57",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "42d2c551",
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_train_contexts = list(filtered_train_contexts)\n",
    "train_questions_sampled = list(train_questions_sampled)\n",
    "filtered_val_contexts = list(filtered_val_contexts)\n",
    "val_questions_sampled = list(val_questions_sampled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "8a205267",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import DistilBertTokenizerFast\n",
    "tokenizer = DistilBertTokenizerFast.from_pretrained('distilbert-base-uncased')\n",
    "train_encodings = tokenizer(filtered_train_contexts, train_questions_sampled, truncation=True, padding=True)\n",
    "val_encodings = tokenizer(filtered_val_contexts, val_questions_sampled, truncation=True, padding=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "2f76bc0e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertForQuestionAnswering: ['vocab_transform.weight', 'vocab_transform.bias', 'vocab_layer_norm.weight', 'vocab_projector.bias', 'vocab_layer_norm.bias']\n",
      "- This IS expected if you are initializing DistilBertForQuestionAnswering from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing DistilBertForQuestionAnswering from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of DistilBertForQuestionAnswering were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['qa_outputs.bias', 'qa_outputs.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "from transformers import DistilBertForQuestionAnswering, AdamW\n",
    "model = DistilBertForQuestionAnswering.from_pretrained('distilbert-base-uncased')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "9d492c69",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_token_positions(encodings, answers):\n",
    "    start_positions = []\n",
    "    end_positions = []\n",
    "    for i in range(len(answers)):\n",
    "        start_pos = encodings.char_to_token(i, answers[i]['answer_start'])\n",
    "        end_pos = encodings.char_to_token(i, answers[i]['answer_end'])\n",
    "\n",
    "        if start_pos is None:\n",
    "            start_pos = tokenizer.model_max_length\n",
    "        if end_pos is None:\n",
    "            shift = 1\n",
    "            while end_pos is None and answers[i]['answer_end'] - shift >= 0:\n",
    "                end_pos = encodings.char_to_token(i, answers[i]['answer_end'] - shift)\n",
    "                shift += 1\n",
    "        if end_pos is None:\n",
    "            end_pos = tokenizer.model_max_length\n",
    "\n",
    "        start_positions.append(start_pos)\n",
    "        end_positions.append(end_pos)\n",
    "        \n",
    "    encodings.update({'start_positions': start_positions, 'end_positions': end_positions})\n",
    "\n",
    "add_token_positions(train_encodings, train_answers_sampled)\n",
    "add_token_positions(val_encodings, val_answers_sampled)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "6b2cca0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "class SquadDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, encodings):\n",
    "        self.encodings = encodings\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.encodings.input_ids)\n",
    "\n",
    "train_dataset = SquadDataset(train_encodings)\n",
    "val_dataset = SquadDataset(val_encodings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "5b73a43d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on GPU: NVIDIA GeForce GTX 1080 Ti\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "from transformers import AdamW\n",
    "from tqdm import tqdm\n",
    "import torch\n",
    "# setup GPU/CPU\n",
    "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
    "if torch.cuda.is_available():\n",
    "    print(\"Running on GPU:\", torch.cuda.get_device_name(0))\n",
    "else:\n",
    "    print(\"Running on CPU\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "57da9edd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 0: 100%|██████████| 313/313 [02:28<00:00,  2.11it/s, loss=1.66]\n",
      "Epoch 1: 100%|██████████| 313/313 [02:29<00:00,  2.09it/s, loss=1.89] \n",
      "Epoch 2: 100%|██████████| 313/313 [02:29<00:00,  2.09it/s, loss=0.696]\n"
     ]
    }
   ],
   "source": [
    "model.to(device)\n",
    "model.train()\n",
    "optim = AdamW(model.parameters(), lr=5e-5)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=16, shuffle=True)\n",
    "\n",
    "for epoch in range(3):\n",
    "    model.train()\n",
    "    loop = tqdm(train_loader, leave=True)\n",
    "    for batch in loop:\n",
    "        optim.zero_grad()\n",
    "        input_ids = batch['input_ids'].to(device)\n",
    "        attention_mask = batch['attention_mask'].to(device)\n",
    "        start_positions = batch['start_positions'].to(device)\n",
    "        end_positions = batch['end_positions'].to(device)\n",
    "        outputs = model(input_ids, attention_mask=attention_mask,\n",
    "                        start_positions=start_positions,\n",
    "                        end_positions=end_positions)\n",
    "        loss = outputs[0]\n",
    "        loss.backward()\n",
    "        optim.step()\n",
    "        loop.set_description(f'Epoch {epoch}')\n",
    "        loop.set_postfix(loss=loss.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "f34aaa54",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on GPU: NVIDIA GeForce GTX 1080 Ti\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "from transformers import AdamW\n",
    "from tqdm import tqdm\n",
    "import torch\n",
    "# setup GPU/CPU\n",
    "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
    "if torch.cuda.is_available():\n",
    "    print(\"Running on GPU:\", torch.cuda.get_device_name(0))\n",
    "else:\n",
    "    print(\"Running on CPU\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "d82cd647",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4736328125"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "model.eval()\n",
    "val_loader = DataLoader(val_dataset, batch_size=16)\n",
    "acc = []\n",
    "for batch in val_loader:\n",
    "    with torch.no_grad():\n",
    "        input_ids = batch['input_ids'].to(device)\n",
    "        attention_mask = batch['attention_mask'].to(device)\n",
    "        start_true = batch['start_positions'].to(device)\n",
    "        end_true = batch['end_positions'].to(device)\n",
    "        outputs = model(input_ids, attention_mask=attention_mask)\n",
    "        start_pred = torch.argmax(outputs['start_logits'], dim=1)\n",
    "        end_pred = torch.argmax(outputs['end_logits'], dim=1)\n",
    "        acc.append(((start_pred == start_true).sum()/len(start_pred)).item())\n",
    "        acc.append(((end_pred == end_true).sum()/len(end_pred)).item())\n",
    "acc = sum(acc)/len(acc)\n",
    "acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "1987cbf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "def calculate_f1(pred_start, pred_end, true_start, true_end):\n",
    "    pred_tokens = set(range(pred_start, pred_end + 1))\n",
    "    true_tokens = set(range(true_start, true_end + 1))\n",
    "\n",
    "    common_tokens = pred_tokens.intersection(true_tokens)\n",
    "    if len(common_tokens) == 0:\n",
    "        return 0, 0, 0  # precision, recall, f1\n",
    "\n",
    "    precision = len(common_tokens) / len(pred_tokens)\n",
    "    recall = len(common_tokens) / len(true_tokens)\n",
    "    f1 = 2 * precision * recall / (precision + recall)\n",
    "    return precision, recall, f1\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "b7b8d1cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "\n",
    "val_loader = DataLoader(val_dataset, batch_size=16)\n",
    "\n",
    "start_acc = []\n",
    "end_acc = []\n",
    "precisions = []\n",
    "recalls = []\n",
    "f1s = []\n",
    "\n",
    "for batch in val_loader:\n",
    "    with torch.no_grad():\n",
    "        input_ids = batch['input_ids'].to(device)\n",
    "        attention_mask = batch['attention_mask'].to(device)\n",
    "        start_true = batch['start_positions'].to(device)\n",
    "        end_true = batch['end_positions'].to(device)\n",
    "        outputs = model(input_ids, attention_mask=attention_mask)\n",
    "        start_pred = torch.argmax(outputs['start_logits'], dim=1)\n",
    "        end_pred = torch.argmax(outputs['end_logits'], dim=1)\n",
    "        start_acc.append((start_pred == start_true).sum().item() / len(start_pred))\n",
    "        end_acc.append((end_pred == end_true).sum().item() / len(end_pred))\n",
    "        for sp, ep, st, et in zip(start_pred, end_pred, start_true, end_true):\n",
    "            precision, recall, f1 = calculate_f1(sp.item(), ep.item(), st.item(), et.item())\n",
    "            precisions.append(precision)\n",
    "            recalls.append(recall)\n",
    "            f1s.append(f1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "63adc667",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "avg_start_acc = sum(start_acc) / len(start_acc)\n",
    "avg_end_acc = sum(end_acc) / len(end_acc)\n",
    "avg_precision = sum(precisions) / len(precisions)\n",
    "avg_recall = sum(recalls) / len(recalls)\n",
    "avg_f1 = sum(f1s) / len(f1s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "ed15dc5e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Start Position Accuracy: 0.4531\n",
      "Average End Position Accuracy: 0.4941\n",
      "Average Precision: 0.4881\n",
      "Average Recall: 0.5996\n",
      "Average F1 Score: 0.4889\n"
     ]
    }
   ],
   "source": [
    "print(f\"Average Start Position Accuracy: {avg_start_acc:.4f}\")\n",
    "print(f\"Average End Position Accuracy: {avg_end_acc:.4f}\")\n",
    "print(f\"Average Precision: {avg_precision:.4f}\")\n",
    "print(f\"Average Recall: {avg_recall:.4f}\")\n",
    "print(f\"Average F1 Score: {avg_f1:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c30be430",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb0067ff",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
