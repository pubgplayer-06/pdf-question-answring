{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a378ad17",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import nltk\n",
    "from nltk.tokenize import sent_tokenize\n",
    "from sklearn.metrics.pairwise import cosine_similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6c9b5aca",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-18 15:31:47.186790: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer,AutoModel\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "02573318",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "def read_squad(path):\n",
    "    with open(path, 'rb') as f:\n",
    "        squad_dict = json.load(f)\n",
    "    contexts = []\n",
    "    questions = []\n",
    "    answers = []\n",
    "\n",
    "    for group in squad_dict['data']:\n",
    "        for passage in group['paragraphs']:\n",
    "            context = passage['context']\n",
    "            for qa in passage['qas']:\n",
    "                question = qa['question']\n",
    "\n",
    "                if 'plausible_answers' in qa.keys():\n",
    "                    access = 'plausible_answers'\n",
    "                else:\n",
    "                    access = 'answers'\n",
    "                for answer in qa[access]:\n",
    "\n",
    "                    contexts.append(context)\n",
    "                    questions.append(question)\n",
    "                    answers.append(answer)\n",
    "    return contexts, questions, answers\n",
    "\n",
    "\n",
    "train_contexts, train_questions, train_answers = read_squad('squad/train-v2.0.json')\n",
    "val_contexts, val_questions, val_answers = read_squad('squad/dev-v2.0.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7a27d10c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install gensim\n",
    "import numpy as np\n",
    "# from gensim.models import Word2Vec\n",
    "np.random.seed(42)\n",
    "train_contexts = np.array(train_contexts)\n",
    "train_questions = np.array(train_questions)\n",
    "train_answers = np.array(train_answers)\n",
    "\n",
    "val_contexts = np.array(val_contexts)\n",
    "val_questions = np.array(val_questions)\n",
    "val_answers = np.array(val_answers)\n",
    "\n",
    "\n",
    "train_indices = np.random.choice(len(train_contexts), 5000, replace=False)\n",
    "val_indices = np.random.choice(len(val_contexts), 500, replace=False)\n",
    "\n",
    "train_contexts_sampled = train_contexts[train_indices]\n",
    "train_questions_sampled = train_questions[train_indices]\n",
    "train_answers_sampled = train_answers[train_indices]\n",
    "\n",
    "val_contexts_sampled = val_contexts[val_indices]\n",
    "val_questions_sampled = val_questions[val_indices]\n",
    "val_answers_sampled = val_answers[val_indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "37881677",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_contexts_sampled = train_contexts_sampled.tolist()\n",
    "train_questions_sampled = train_questions_sampled.tolist()\n",
    "train_answers_sampled =train_answers_sampled.tolist()\n",
    "\n",
    "val_contexts_sampled = val_contexts_sampled.tolist()\n",
    "val_questions_sampled = val_questions_sampled.tolist()\n",
    "val_answers_sampled = val_answers_sampled.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0904210e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_end_idx(answers, contexts):\n",
    "    for answer, context in zip(answers, contexts):\n",
    "        gold_text = answer['text']\n",
    "        start_idx = answer['answer_start']\n",
    "        end_idx = start_idx + len(gold_text)\n",
    "\n",
    "        if context[start_idx:end_idx] == gold_text:\n",
    "            answer['answer_end'] = end_idx\n",
    "        else:\n",
    "            for n in [1, 2]:\n",
    "                if context[start_idx-n:end_idx-n] == gold_text:\n",
    "                    answer['answer_start'] = start_idx - n\n",
    "                    answer['answer_end'] = end_idx - n\n",
    "\n",
    "add_end_idx(train_answers_sampled, train_contexts_sampled)\n",
    "add_end_idx(val_answers_sampled, val_contexts_sampled)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "027adaa1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /home/kunuruabhishek/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "from nltk.corpus import stopwords\n",
    "stop_words = stopwords.words('english')\n",
    "from nltk.stem import SnowballStemmer\n",
    "stemmer = SnowballStemmer('english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "25b0a493",
   "metadata": {},
   "outputs": [],
   "source": [
    "import regex as re\n",
    "text_cleaning_re = \"@\\S+|https?:\\S+|http?:\\S|[^A-Za-z0-9]+\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "48630a73",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(text, stem=True):\n",
    "  text = re.sub(text_cleaning_re, ' ', str(text).lower()).strip()\n",
    "  tokens = []\n",
    "  for token in text.split():\n",
    "    if token not in stop_words:\n",
    "      if stem:\n",
    "        tokens.append(stemmer.stem(token))\n",
    "      else:\n",
    "        tokens.append(token)\n",
    "  return \" \".join(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "21943c4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from tqdm import tqdm\n",
    "from nltk.tokenize import sent_tokenize\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e79d1147",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.seq_relationship.weight', 'cls.predictions.transform.dense.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "model_name='bert-base-uncased'\n",
    "model=AutoModel.from_pretrained(model_name)\n",
    "tokenizer=AutoTokenizer.from_pretrained(model_name)\n",
    "\n",
    "def calculate_similarity_scores(context_sentences, question):\n",
    "    sentences = context_sentences + [question]\n",
    "    tokens={'input_ids':[],'attention_mask':[]}\n",
    "    for sentence in sentences:\n",
    "        new_tokens=tokenizer.encode_plus(sentence,max_length=128,\n",
    "                                    truncation=True,padding='max_length',\n",
    "                                    return_tensors='pt')\n",
    "        tokens['input_ids'].append(new_tokens['input_ids'][0])\n",
    "        tokens['attention_mask'].append(new_tokens['attention_mask'][0])\n",
    "    tokens['input_ids']=torch.stack(tokens['input_ids'])\n",
    "    tokens['attention_mask']=torch.stack(tokens['attention_mask'])\n",
    "    outputs =model(**tokens)\n",
    "    \n",
    "    embeddings =outputs['last_hidden_state']\n",
    "    attention =tokens['attention_mask']\n",
    "    \n",
    "    mask=attention.unsqueeze(-1).expand(embeddings.shape).float()\n",
    "    mask_embeddings=embeddings*mask\n",
    "    \n",
    "    summed=torch.sum(mask_embeddings,1)\n",
    "    counts=torch.clamp(mask.sum(1),min=1e-9)\n",
    "    mean_pooled=summed/counts\n",
    "    mean_pooled=mean_pooled.detach().numpy()\n",
    "    question_vector = [mean_pooled[-1]]\n",
    "    context_vectors = mean_pooled[:-1]\n",
    "\n",
    "    similarity_scores = cosine_similarity(question_vector, context_vectors).flatten()\n",
    "    return similarity_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6eb7af4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def filter_context_by_similarity(context_sentences, similarity_scores, threshold):\n",
    "    filtered_indices = np.where(similarity_scores > threshold)[0]\n",
    "    if len(filtered_indices) == 0:\n",
    "        return ' '.join(context_sentences)\n",
    "    filtered_sentences = [context_sentences[i] for i in filtered_indices]\n",
    "    return ' '.join(filtered_sentences)\n",
    "\n",
    "def filter_squad_contexts(contexts, questions, threshold=0.5):\n",
    "    filtered_contexts = []\n",
    "    for context, question in tqdm(zip(contexts, questions), total=len(contexts)):\n",
    "        context_sentences = sent_tokenize(context)\n",
    "        preprocessed_sentences = [preprocess(sentence) for sentence in context_sentences]\n",
    "        preprocessed_question = preprocess(question)\n",
    "        similarity_scores = calculate_similarity_scores(preprocessed_sentences, preprocessed_question)\n",
    "        filtered_context = filter_context_by_similarity(context_sentences, similarity_scores, threshold)\n",
    "        filtered_contexts.append(filtered_context)\n",
    "    return filtered_contexts\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "74ed7505",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5000/5000 [54:05<00:00,  1.54it/s]  \n",
      "100%|██████████| 500/500 [05:45<00:00,  1.45it/s]\n"
     ]
    }
   ],
   "source": [
    "filtered_train_contexts = filter_squad_contexts(train_contexts_sampled, train_questions_sampled)\n",
    "filtered_val_contexts = filter_squad_contexts(val_contexts_sampled, val_questions_sampled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7f50e7e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipped 0 examples where the answer could not be found in the truncated context.\n"
     ]
    }
   ],
   "source": [
    "def align_answers_with_context(original_contexts, updated_contexts, answers):\n",
    "    new_contexts = []\n",
    "    aligned_answers = []\n",
    "    skipped_count = 0\n",
    "\n",
    "    for orig_context, updated_context, answer in zip(original_contexts, updated_contexts, answers):\n",
    "        start_pos = answer['answer_start']\n",
    "        end_pos = answer['answer_end']\n",
    "        orig_answer = orig_context[start_pos:end_pos]\n",
    "        start_idx = updated_context.find(orig_answer)\n",
    "\n",
    "        if start_idx == -1:\n",
    "            skipped_count += 1\n",
    "\n",
    "            modified_answer = answer.copy()\n",
    "            modified_answer['answer_start'] = len(updated_contexts)\n",
    "            modified_answer['answer_end'] = len(updated_contexts)\n",
    "        else:\n",
    "            new_start_pos = start_idx\n",
    "            new_end_pos = start_idx + len(orig_answer)\n",
    "            modified_answer = answer.copy()\n",
    "            modified_answer['answer_start'] = new_start_pos\n",
    "            modified_answer['answer_end'] = new_end_pos\n",
    "\n",
    "        aligned_answers.append(modified_answer)\n",
    "        new_contexts.append(updated_context)\n",
    "\n",
    "    return new_contexts, aligned_answers, skipped_count\n",
    "\n",
    "filtered_train_contexts, train_answers_sampled, skipped_count = align_answers_with_context(train_contexts_sampled, filtered_train_contexts, train_answers_sampled)\n",
    "print(f'Skipped {skipped_count} examples where the answer could not be found in the truncated context.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "fa4b1c1a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipped 0 examples (0.00%) where the answer could not be found in the truncated context.\n"
     ]
    }
   ],
   "source": [
    "total_contexts = len(train_contexts_sampled) \n",
    "\n",
    "skipped_percentage = (skipped_count / total_contexts) * 100\n",
    "print(f'Skipped {skipped_count} examples ({skipped_percentage:.2f}%) where the answer could not be found in the truncated context.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ca76f571",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"The first Sky television rights agreement was worth £304 million over five seasons. The next contract, negotiated to start from the 1997–98 season, rose to £670 million over four seasons. The third contract was a £1.024 billion deal with BSkyB for the three seasons from 2001–02 to 2003–04. The league brought in £320 million from the sale of its international rights for the three-year period from 2004–05 to 2006–07. It sold the rights itself on a territory-by-territory basis. Sky's monopoly was broken from August 2006 when Setanta Sports was awarded rights to show two out of the six packages of matches available. This occurred following an insistence by the European Commission that exclusive rights should not be sold to one television company. Sky and Setanta paid a total of £1.7 billion, a two-thirds increase which took many commentators by surprise as it had been widely assumed that the value of the rights had levelled off following many years of rapid growth. Setanta also hold rights to a live 3 pm match solely for Irish viewers. The BBC has retained the rights to show highlights for the same three seasons (on Match of the Day) for £171.6 million, a 63 per cent increase on the £105 million it paid for the previous three-year period. Sky and BT have agreed to jointly pay £84.3 million for delayed television rights to 242 games (that is the right to broadcast them in full on television and over the internet) in most cases for a period of 50 hours after 10 pm on matchday. Overseas television rights fetched £625 million, nearly double the previous contract. The total raised from these deals is more than £2.7 billion, giving Premier League clubs an average media income from league games of around £40 million-a-year from 2007 to 2010.\""
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filtered_train_contexts[12]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d25e1584",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"The first Sky television rights agreement was worth £304 million over five seasons. The next contract, negotiated to start from the 1997–98 season, rose to £670 million over four seasons. The third contract was a £1.024 billion deal with BSkyB for the three seasons from 2001–02 to 2003–04. The league brought in £320 million from the sale of its international rights for the three-year period from 2004–05 to 2006–07. It sold the rights itself on a territory-by-territory basis. Sky's monopoly was broken from August 2006 when Setanta Sports was awarded rights to show two out of the six packages of matches available. This occurred following an insistence by the European Commission that exclusive rights should not be sold to one television company. Sky and Setanta paid a total of £1.7 billion, a two-thirds increase which took many commentators by surprise as it had been widely assumed that the value of the rights had levelled off following many years of rapid growth. Setanta also hold rights to a live 3 pm match solely for Irish viewers. The BBC has retained the rights to show highlights for the same three seasons (on Match of the Day) for £171.6 million, a 63 per cent increase on the £105 million it paid for the previous three-year period. Sky and BT have agreed to jointly pay £84.3 million for delayed television rights to 242 games (that is the right to broadcast them in full on television and over the internet) in most cases for a period of 50 hours after 10 pm on matchday. Overseas television rights fetched £625 million, nearly double the previous contract. The total raised from these deals is more than £2.7 billion, giving Premier League clubs an average media income from league games of around £40 million-a-year from 2007 to 2010.\""
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_contexts[train_indices[12]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "85ed50f5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'How much many did the Premier League make from selling its internation rights during 2004-07?'"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_questions_sampled[12]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c38aa60",
   "metadata": {},
   "source": [
    "### after sentence selector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f57823af",
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_train_contexts = list(filtered_train_contexts)\n",
    "train_questions_sampled = list(train_questions_sampled)\n",
    "filtered_val_contexts = list(filtered_val_contexts)\n",
    "val_questions_sampled = list(val_questions_sampled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "f2160a58",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import DistilBertTokenizerFast\n",
    "tokenizer = DistilBertTokenizerFast.from_pretrained('distilbert-base-uncased')\n",
    "train_encodings = tokenizer(filtered_train_contexts, train_questions_sampled, truncation=True, padding=True)\n",
    "val_encodings = tokenizer(filtered_val_contexts, val_questions_sampled, truncation=True, padding=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "3231691c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertForQuestionAnswering: ['vocab_projector.bias', 'vocab_layer_norm.weight', 'vocab_transform.weight', 'vocab_transform.bias', 'vocab_layer_norm.bias']\n",
      "- This IS expected if you are initializing DistilBertForQuestionAnswering from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing DistilBertForQuestionAnswering from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of DistilBertForQuestionAnswering were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['qa_outputs.bias', 'qa_outputs.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "from transformers import DistilBertForQuestionAnswering, AdamW\n",
    "model = DistilBertForQuestionAnswering.from_pretrained('distilbert-base-uncased')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "693d6196",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_token_positions(encodings, answers):\n",
    "    start_positions = []\n",
    "    end_positions = []\n",
    "    for i in range(len(answers)):\n",
    "        start_pos = encodings.char_to_token(i, answers[i]['answer_start'])\n",
    "        end_pos = encodings.char_to_token(i, answers[i]['answer_end'])\n",
    "\n",
    "        if start_pos is None:\n",
    "            start_pos = tokenizer.model_max_length\n",
    "        if end_pos is None:\n",
    "            shift = 1\n",
    "            while end_pos is None and answers[i]['answer_end'] - shift >= 0:\n",
    "                end_pos = encodings.char_to_token(i, answers[i]['answer_end'] - shift)\n",
    "                shift += 1\n",
    "        if end_pos is None:\n",
    "            end_pos = tokenizer.model_max_length\n",
    "\n",
    "        start_positions.append(start_pos)\n",
    "        end_positions.append(end_pos)\n",
    "        \n",
    "    encodings.update({'start_positions': start_positions, 'end_positions': end_positions})\n",
    "\n",
    "add_token_positions(train_encodings, train_answers_sampled)\n",
    "add_token_positions(val_encodings, val_answers_sampled)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "6ec12421",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "class SquadDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, encodings):\n",
    "        self.encodings = encodings\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.encodings.input_ids)\n",
    "\n",
    "train_dataset = SquadDataset(train_encodings)\n",
    "val_dataset = SquadDataset(val_encodings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "0a505631",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on GPU: NVIDIA GeForce GTX 1080 Ti\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "from transformers import AdamW\n",
    "from tqdm import tqdm\n",
    "import torch\n",
    "\n",
    "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
    "if torch.cuda.is_available():\n",
    "    print(\"Running on GPU:\", torch.cuda.get_device_name(0))\n",
    "else:\n",
    "    print(\"Running on CPU\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "66e172aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 0: 100%|██████████| 313/313 [02:24<00:00,  2.17it/s, loss=2.99]\n",
      "Epoch 1: 100%|██████████| 313/313 [02:28<00:00,  2.11it/s, loss=1.49] \n",
      "Epoch 2: 100%|██████████| 313/313 [02:28<00:00,  2.10it/s, loss=0.382]\n"
     ]
    }
   ],
   "source": [
    "model.to(device)\n",
    "model.train()\n",
    "optim = AdamW(model.parameters(), lr=5e-5)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=16, shuffle=True)\n",
    "\n",
    "for epoch in range(3):\n",
    "    model.train()\n",
    "    loop = tqdm(train_loader, leave=True)\n",
    "    for batch in loop:\n",
    "        optim.zero_grad()\n",
    "        input_ids = batch['input_ids'].to(device)\n",
    "        attention_mask = batch['attention_mask'].to(device)\n",
    "        start_positions = batch['start_positions'].to(device)\n",
    "        end_positions = batch['end_positions'].to(device)\n",
    "        outputs = model(input_ids, attention_mask=attention_mask,\n",
    "                        start_positions=start_positions,\n",
    "                        end_positions=end_positions)\n",
    "        loss = outputs[0]\n",
    "        loss.backward()\n",
    "        optim.step()\n",
    "        loop.set_description(f'Epoch {epoch}')\n",
    "        loop.set_postfix(loss=loss.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "0acb1903",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.474609375"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "model.eval()\n",
    "val_loader = DataLoader(val_dataset, batch_size=16)\n",
    "acc = []\n",
    "for batch in val_loader:\n",
    "    with torch.no_grad():\n",
    "        input_ids = batch['input_ids'].to(device)\n",
    "        attention_mask = batch['attention_mask'].to(device)\n",
    "        start_true = batch['start_positions'].to(device)\n",
    "        end_true = batch['end_positions'].to(device)\n",
    "        outputs = model(input_ids, attention_mask=attention_mask)\n",
    "        start_pred = torch.argmax(outputs['start_logits'], dim=1)\n",
    "        end_pred = torch.argmax(outputs['end_logits'], dim=1)\n",
    "        acc.append(((start_pred == start_true).sum()/len(start_pred)).item())\n",
    "        acc.append(((end_pred == end_true).sum()/len(end_pred)).item())\n",
    "acc = sum(acc)/len(acc)\n",
    "acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "e33bed03",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "def calculate_f1(pred_start, pred_end, true_start, true_end):\n",
    "    pred_tokens = set(range(pred_start, pred_end + 1))\n",
    "    true_tokens = set(range(true_start, true_end + 1))\n",
    "\n",
    "    common_tokens = pred_tokens.intersection(true_tokens)\n",
    "    if len(common_tokens) == 0:\n",
    "        return 0, 0, 0  \n",
    "\n",
    "    precision = len(common_tokens) / len(pred_tokens)\n",
    "    recall = len(common_tokens) / len(true_tokens)\n",
    "    f1 = 2 * precision * recall / (precision + recall)\n",
    "    return precision, recall, f1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "affd9c9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "\n",
    "val_loader = DataLoader(val_dataset, batch_size=16)\n",
    "\n",
    "start_acc = []\n",
    "end_acc = []\n",
    "precisions = []\n",
    "recalls = []\n",
    "f1s = []\n",
    "\n",
    "for batch in val_loader:\n",
    "    with torch.no_grad():\n",
    "        input_ids = batch['input_ids'].to(device)\n",
    "        attention_mask = batch['attention_mask'].to(device)\n",
    "        start_true = batch['start_positions'].to(device)\n",
    "        end_true = batch['end_positions'].to(device)\n",
    "        outputs = model(input_ids, attention_mask=attention_mask)\n",
    "        start_pred = torch.argmax(outputs['start_logits'], dim=1)\n",
    "        end_pred = torch.argmax(outputs['end_logits'], dim=1)\n",
    "        start_acc.append((start_pred == start_true).sum().item() / len(start_pred))\n",
    "        end_acc.append((end_pred == end_true).sum().item() / len(end_pred))\n",
    "        for sp, ep, st, et in zip(start_pred, end_pred, start_true, end_true):\n",
    "            precision, recall, f1 = calculate_f1(sp.item(), ep.item(), st.item(), et.item())\n",
    "            precisions.append(precision)\n",
    "            recalls.append(recall)\n",
    "            f1s.append(f1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "cc9f8280",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "avg_start_acc = sum(start_acc) / len(start_acc)\n",
    "avg_end_acc = sum(end_acc) / len(end_acc)\n",
    "avg_precision = sum(precisions) / len(precisions)\n",
    "avg_recall = sum(recalls) / len(recalls)\n",
    "avg_f1 = sum(f1s) / len(f1s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "dfe0900b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Start Position Accuracy: 0.4648\n",
      "Average End Position Accuracy: 0.4844\n",
      "Average Precision: 0.4791\n",
      "Average Recall: 0.5864\n",
      "Average F1 Score: 0.4791\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(f\"Average Start Position Accuracy: {avg_start_acc:.4f}\")\n",
    "print(f\"Average End Position Accuracy: {avg_end_acc:.4f}\")\n",
    "print(f\"Average Precision: {avg_precision:.4f}\")\n",
    "print(f\"Average Recall: {avg_recall:.4f}\")\n",
    "print(f\"Average F1 Score: {avg_f1:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e63cb5c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2660aa8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
