{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "20ed3a35",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import nltk\n",
    "from nltk.tokenize import sent_tokenize\n",
    "from sklearn.metrics.pairwise import cosine_similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2a447829",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-18 14:53:47.762729: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer,AutoModel\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0dacdcad",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "def read_squad(path):\n",
    "    with open(path, 'rb') as f:\n",
    "        squad_dict = json.load(f)\n",
    "    contexts = []\n",
    "    questions = []\n",
    "    answers = []\n",
    "\n",
    "    for group in squad_dict['data']:\n",
    "        for passage in group['paragraphs']:\n",
    "            context = passage['context']\n",
    "            for qa in passage['qas']:\n",
    "                question = qa['question']\n",
    "\n",
    "                if 'plausible_answers' in qa.keys():\n",
    "                    access = 'plausible_answers'\n",
    "                else:\n",
    "                    access = 'answers'\n",
    "                for answer in qa[access]:\n",
    "\n",
    "                    contexts.append(context)\n",
    "                    questions.append(question)\n",
    "                    answers.append(answer)\n",
    "    return contexts, questions, answers\n",
    "\n",
    "\n",
    "train_contexts, train_questions, train_answers = read_squad('squad/train-v2.0.json')\n",
    "val_contexts, val_questions, val_answers = read_squad('squad/dev-v2.0.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b5d53eba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install gensim\n",
    "import numpy as np\n",
    "# from gensim.models import Word2Vec\n",
    "np.random.seed(42)\n",
    "train_contexts = np.array(train_contexts)\n",
    "train_questions = np.array(train_questions)\n",
    "train_answers = np.array(train_answers)\n",
    "\n",
    "val_contexts = np.array(val_contexts)\n",
    "val_questions = np.array(val_questions)\n",
    "val_answers = np.array(val_answers)\n",
    "\n",
    "\n",
    "train_indices = np.random.choice(len(train_contexts), 5000, replace=False)\n",
    "val_indices = np.random.choice(len(val_contexts), 500, replace=False)\n",
    "\n",
    "train_contexts_sampled = train_contexts[train_indices]\n",
    "train_questions_sampled = train_questions[train_indices]\n",
    "train_answers_sampled = train_answers[train_indices]\n",
    "\n",
    "val_contexts_sampled = val_contexts[val_indices]\n",
    "val_questions_sampled = val_questions[val_indices]\n",
    "val_answers_sampled = val_answers[val_indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "739ccbc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_contexts_sampled = train_contexts_sampled.tolist()\n",
    "train_questions_sampled = train_questions_sampled.tolist()\n",
    "train_answers_sampled =train_answers_sampled.tolist()\n",
    "\n",
    "val_contexts_sampled = val_contexts_sampled.tolist()\n",
    "val_questions_sampled = val_questions_sampled.tolist()\n",
    "val_answers_sampled = val_answers_sampled.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1ef97cf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_end_idx(answers, contexts):\n",
    "    for answer, context in zip(answers, contexts):\n",
    "        gold_text = answer['text']\n",
    "        start_idx = answer['answer_start']\n",
    "        end_idx = start_idx + len(gold_text)\n",
    "\n",
    "        if context[start_idx:end_idx] == gold_text:\n",
    "            answer['answer_end'] = end_idx\n",
    "        else:\n",
    "            for n in [1, 2]:\n",
    "                if context[start_idx-n:end_idx-n] == gold_text:\n",
    "                    answer['answer_start'] = start_idx - n\n",
    "                    answer['answer_end'] = end_idx - n\n",
    "\n",
    "add_end_idx(train_answers_sampled, train_contexts_sampled)\n",
    "add_end_idx(val_answers_sampled, val_contexts_sampled)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "01003411",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /home/kunuruabhishek/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "from nltk.corpus import stopwords\n",
    "stop_words = stopwords.words('english')\n",
    "from nltk.stem import SnowballStemmer\n",
    "stemmer = SnowballStemmer('english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4d585006",
   "metadata": {},
   "outputs": [],
   "source": [
    "import regex as re\n",
    "text_cleaning_re = \"@\\S+|https?:\\S+|http?:\\S|[^A-Za-z0-9]+\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e4ab44cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(text, stem=True):\n",
    "  text = re.sub(text_cleaning_re, ' ', str(text).lower()).strip()\n",
    "  tokens = []\n",
    "  for token in text.split():\n",
    "    if token not in stop_words:\n",
    "      if stem:\n",
    "        tokens.append(stemmer.stem(token))\n",
    "      else:\n",
    "        tokens.append(token)\n",
    "  return \" \".join(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1996baed",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "2024-06-18 14:53:57.503287: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set\n",
      "2024-06-18 14:53:57.503451: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcuda.so.1\n",
      "2024-06-18 14:53:57.809042: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2024-06-18 14:53:57.809999: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: \n",
      "pciBusID: 0000:0a:00.0 name: NVIDIA GeForce GTX 1080 Ti computeCapability: 6.1\n",
      "coreClock: 1.582GHz coreCount: 28 deviceMemorySize: 10.92GiB deviceMemoryBandwidth: 451.17GiB/s\n",
      "2024-06-18 14:53:57.810064: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2024-06-18 14:53:57.810964: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 1 with properties: \n",
      "pciBusID: 0000:41:00.0 name: NVIDIA GeForce GTX 1080 Ti computeCapability: 6.1\n",
      "coreClock: 1.582GHz coreCount: 28 deviceMemorySize: 10.92GiB deviceMemoryBandwidth: 451.17GiB/s\n",
      "2024-06-18 14:53:57.811022: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2024-06-18 14:53:57.811688: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 2 with properties: \n",
      "pciBusID: 0000:42:00.0 name: NVIDIA GeForce GTX 1080 Ti computeCapability: 6.1\n",
      "coreClock: 1.582GHz coreCount: 28 deviceMemorySize: 10.91GiB deviceMemoryBandwidth: 451.17GiB/s\n",
      "2024-06-18 14:53:57.811710: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0\n",
      "2024-06-18 14:53:57.811750: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.11\n",
      "2024-06-18 14:53:57.811773: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.11\n",
      "2024-06-18 14:53:57.812545: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10\n",
      "2024-06-18 14:53:57.812755: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10\n",
      "2024-06-18 14:53:57.812809: W tensorflow/stream_executor/platform/default/dso_loader.cc:60] Could not load dynamic library 'libcusolver.so.10'; dlerror: libcusolver.so.10: cannot open shared object file: No such file or directory\n",
      "2024-06-18 14:53:57.813303: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.11\n",
      "2024-06-18 14:53:57.813339: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.8\n",
      "2024-06-18 14:53:57.813345: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1757] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n",
      "2024-06-18 14:53:57.813723: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-06-18 14:53:57.815532: I tensorflow/compiler/jit/xla_gpu_device.cc:99] Not creating XLA devices, tf_xla_enable_xla_devices not set\n",
      "2024-06-18 14:53:57.815553: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1261] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
      "2024-06-18 14:53:57.815558: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1267]      \n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "from keras.models import Sequential\n",
    "from keras.layers import LSTM, Dense, Bidirectional\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained('bert-base-uncased')\n",
    "bert_model = AutoModel.from_pretrained('bert-base-uncased')\n",
    "lstm_model = Sequential()\n",
    "lstm_model.add(Bidirectional(LSTM(100, input_shape=(1, 768), return_sequences=False)))\n",
    "lstm_model.add(Dense(100, activation='relu'))\n",
    "lstm_model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0b0c5da5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_similarity_scores(context_sentences, question):\n",
    "    sentences = context_sentences + [question]\n",
    "    tokens = {'input_ids': [], 'attention_mask': []}\n",
    "\n",
    "    for sentence in sentences:\n",
    "        new_tokens = tokenizer.encode_plus(sentence, max_length=128,\n",
    "                                           truncation=True, padding='max_length',\n",
    "                                           return_tensors='pt')\n",
    "        tokens['input_ids'].append(new_tokens['input_ids'][0])\n",
    "        tokens['attention_mask'].append(new_tokens['attention_mask'][0])\n",
    "\n",
    "    tokens['input_ids'] = torch.stack(tokens['input_ids'])\n",
    "    tokens['attention_mask'] = torch.stack(tokens['attention_mask'])\n",
    "\n",
    "    with torch.no_grad():\n",
    "        outputs = bert_model(**tokens)\n",
    "\n",
    "    embeddings = outputs.last_hidden_state\n",
    "    attention = tokens['attention_mask']\n",
    "\n",
    "    mask = attention.unsqueeze(-1).expand(embeddings.shape).float()\n",
    "    mask_embeddings = embeddings * mask\n",
    "\n",
    "    summed = torch.sum(mask_embeddings, 1)\n",
    "    counts = torch.clamp(mask.sum(1), min=1e-9)\n",
    "    mean_pooled = summed / counts\n",
    "    mean_pooled = mean_pooled.detach().numpy()\n",
    "    \n",
    "    mean_pooled = np.expand_dims(mean_pooled, axis=1)  \n",
    "\n",
    "    lstm_embeddings = lstm_model.predict(mean_pooled)\n",
    "\n",
    "    question_vector = lstm_embeddings[-1].reshape(1, -1)\n",
    "    context_vectors = lstm_embeddings[:-1]\n",
    "\n",
    "    similarity_scores = cosine_similarity(context_vectors, question_vector).flatten()\n",
    "    return similarity_scores\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5209b7d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/5000 [00:00<?, ?it/s]2024-06-18 14:53:58.394000: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:116] None of the MLIR optimization passes are enabled (registered 2)\n",
      "2024-06-18 14:53:58.394344: I tensorflow/core/platform/profile_utils/cpu_utils.cc:112] CPU Frequency: 3393250000 Hz\n",
      "100%|██████████| 5000/5000 [56:11<00:00,  1.48it/s]  \n",
      "100%|██████████| 500/500 [05:57<00:00,  1.40it/s]\n"
     ]
    }
   ],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from tqdm import tqdm\n",
    "from nltk.tokenize import sent_tokenize\n",
    "import numpy as np\n",
    "def filter_context_by_similarity(context_sentences, similarity_scores, threshold):\n",
    "    filtered_indices = np.where(similarity_scores > threshold)[0]\n",
    "    if len(filtered_indices) == 0:\n",
    "        return ' '.join(context_sentences)\n",
    "    filtered_sentences = [context_sentences[i] for i in filtered_indices]\n",
    "    return ' '.join(filtered_sentences)\n",
    "\n",
    "def filter_squad_contexts(contexts, questions, threshold=0.5):\n",
    "    filtered_contexts = []\n",
    "    for context, question in tqdm(zip(contexts, questions), total=len(contexts)):\n",
    "        context_sentences = sent_tokenize(context)\n",
    "        similarity_scores = calculate_similarity_scores(context_sentences, question)\n",
    "        filtered_context = filter_context_by_similarity(context_sentences, similarity_scores, threshold)\n",
    "        filtered_contexts.append(filtered_context)\n",
    "    return filtered_contexts\n",
    "\n",
    "\n",
    "filtered_train_contexts = filter_squad_contexts(train_contexts_sampled, train_questions_sampled)\n",
    "filtered_val_contexts = filter_squad_contexts(val_contexts_sampled, val_questions_sampled)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "23d08c6c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipped 13 examples where the answer could not be found in the truncated context.\n"
     ]
    }
   ],
   "source": [
    "def align_answers_with_context(original_contexts, updated_contexts, answers):\n",
    "    new_contexts = []\n",
    "    aligned_answers = []\n",
    "    skipped_count = 0\n",
    "\n",
    "    for orig_context, updated_context, answer in zip(original_contexts, updated_contexts, answers):\n",
    "        start_pos = answer['answer_start']\n",
    "        end_pos = answer['answer_end']\n",
    "        orig_answer = orig_context[start_pos:end_pos]\n",
    "        start_idx = updated_context.find(orig_answer)\n",
    "\n",
    "        if start_idx == -1:\n",
    "            skipped_count += 1\n",
    "\n",
    "            modified_answer = answer.copy()\n",
    "            modified_answer['answer_start'] = len(updated_contexts)\n",
    "            modified_answer['answer_end'] = len(updated_contexts)\n",
    "        else:\n",
    "            new_start_pos = start_idx\n",
    "            new_end_pos = start_idx + len(orig_answer)\n",
    "            # Create a copy of answer and update positions\n",
    "            modified_answer = answer.copy()\n",
    "            modified_answer['answer_start'] = new_start_pos\n",
    "            modified_answer['answer_end'] = new_end_pos\n",
    "\n",
    "        aligned_answers.append(modified_answer)\n",
    "        new_contexts.append(updated_context)\n",
    "\n",
    "    return new_contexts, aligned_answers, skipped_count\n",
    "\n",
    "filtered_train_contexts, train_answers_sampled, skipped_count = align_answers_with_context(train_contexts_sampled, filtered_train_contexts, train_answers_sampled)\n",
    "print(f'Skipped {skipped_count} examples where the answer could not be found in the truncated context.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "02c7a181",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipped 13 examples (0.26%) where the answer could not be found in the truncated context.\n"
     ]
    }
   ],
   "source": [
    "total_contexts = len(train_contexts_sampled) \n",
    "\n",
    "skipped_percentage = (skipped_count / total_contexts) * 100\n",
    "print(f'Skipped {skipped_count} examples ({skipped_percentage:.2f}%) where the answer could not be found in the truncated context.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ab05eda3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"The first Sky television rights agreement was worth £304 million over five seasons. The next contract, negotiated to start from the 1997–98 season, rose to £670 million over four seasons. The third contract was a £1.024 billion deal with BSkyB for the three seasons from 2001–02 to 2003–04. The league brought in £320 million from the sale of its international rights for the three-year period from 2004–05 to 2006–07. It sold the rights itself on a territory-by-territory basis. Sky's monopoly was broken from August 2006 when Setanta Sports was awarded rights to show two out of the six packages of matches available. This occurred following an insistence by the European Commission that exclusive rights should not be sold to one television company. Sky and Setanta paid a total of £1.7 billion, a two-thirds increase which took many commentators by surprise as it had been widely assumed that the value of the rights had levelled off following many years of rapid growth. Setanta also hold rights to a live 3 pm match solely for Irish viewers. The BBC has retained the rights to show highlights for the same three seasons (on Match of the Day) for £171.6 million, a 63 per cent increase on the £105 million it paid for the previous three-year period. Sky and BT have agreed to jointly pay £84.3 million for delayed television rights to 242 games (that is the right to broadcast them in full on television and over the internet) in most cases for a period of 50 hours after 10 pm on matchday. Overseas television rights fetched £625 million, nearly double the previous contract. The total raised from these deals is more than £2.7 billion, giving Premier League clubs an average media income from league games of around £40 million-a-year from 2007 to 2010.\""
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filtered_train_contexts[12]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "83ff4775",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"The first Sky television rights agreement was worth £304 million over five seasons. The next contract, negotiated to start from the 1997–98 season, rose to £670 million over four seasons. The third contract was a £1.024 billion deal with BSkyB for the three seasons from 2001–02 to 2003–04. The league brought in £320 million from the sale of its international rights for the three-year period from 2004–05 to 2006–07. It sold the rights itself on a territory-by-territory basis. Sky's monopoly was broken from August 2006 when Setanta Sports was awarded rights to show two out of the six packages of matches available. This occurred following an insistence by the European Commission that exclusive rights should not be sold to one television company. Sky and Setanta paid a total of £1.7 billion, a two-thirds increase which took many commentators by surprise as it had been widely assumed that the value of the rights had levelled off following many years of rapid growth. Setanta also hold rights to a live 3 pm match solely for Irish viewers. The BBC has retained the rights to show highlights for the same three seasons (on Match of the Day) for £171.6 million, a 63 per cent increase on the £105 million it paid for the previous three-year period. Sky and BT have agreed to jointly pay £84.3 million for delayed television rights to 242 games (that is the right to broadcast them in full on television and over the internet) in most cases for a period of 50 hours after 10 pm on matchday. Overseas television rights fetched £625 million, nearly double the previous contract. The total raised from these deals is more than £2.7 billion, giving Premier League clubs an average media income from league games of around £40 million-a-year from 2007 to 2010.\""
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_contexts[train_indices[12]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "acb2d58c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'How much many did the Premier League make from selling its internation rights during 2004-07?'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_questions_sampled[12]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c894172",
   "metadata": {},
   "source": [
    "### after sentence selector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "197e8896",
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_train_contexts = list(filtered_train_contexts)\n",
    "train_questions_sampled = list(train_questions_sampled)\n",
    "filtered_val_contexts = list(filtered_val_contexts)\n",
    "val_questions_sampled = list(val_questions_sampled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "fd7947cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import DistilBertTokenizerFast\n",
    "tokenizer = DistilBertTokenizerFast.from_pretrained('distilbert-base-uncased')\n",
    "train_encodings = tokenizer(filtered_train_contexts, train_questions_sampled, truncation=True, padding=True)\n",
    "val_encodings = tokenizer(filtered_val_contexts, val_questions_sampled, truncation=True, padding=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "6b008da0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertForQuestionAnswering: ['vocab_transform.weight', 'vocab_layer_norm.bias', 'vocab_transform.bias', 'vocab_projector.bias', 'vocab_layer_norm.weight']\n",
      "- This IS expected if you are initializing DistilBertForQuestionAnswering from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing DistilBertForQuestionAnswering from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of DistilBertForQuestionAnswering were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['qa_outputs.weight', 'qa_outputs.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "from transformers import DistilBertForQuestionAnswering, AdamW\n",
    "model = DistilBertForQuestionAnswering.from_pretrained('distilbert-base-uncased')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "70584411",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_token_positions(encodings, answers):\n",
    "    start_positions = []\n",
    "    end_positions = []\n",
    "    for i in range(len(answers)):\n",
    "        start_pos = encodings.char_to_token(i, answers[i]['answer_start'])\n",
    "        end_pos = encodings.char_to_token(i, answers[i]['answer_end'])\n",
    "\n",
    "        if start_pos is None:\n",
    "            start_pos = tokenizer.model_max_length\n",
    "        if end_pos is None:\n",
    "            shift = 1\n",
    "            while end_pos is None and answers[i]['answer_end'] - shift >= 0:\n",
    "                end_pos = encodings.char_to_token(i, answers[i]['answer_end'] - shift)\n",
    "                shift += 1\n",
    "        if end_pos is None:\n",
    "            end_pos = tokenizer.model_max_length\n",
    "\n",
    "        start_positions.append(start_pos)\n",
    "        end_positions.append(end_pos)\n",
    "        \n",
    "    encodings.update({'start_positions': start_positions, 'end_positions': end_positions})\n",
    "\n",
    "add_token_positions(train_encodings, train_answers_sampled)\n",
    "add_token_positions(val_encodings, val_answers_sampled)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "e1bab554",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "class SquadDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, encodings):\n",
    "        self.encodings = encodings\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.encodings.input_ids)\n",
    "\n",
    "train_dataset = SquadDataset(train_encodings)\n",
    "val_dataset = SquadDataset(val_encodings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "f005ab41",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on GPU: NVIDIA GeForce GTX 1080 Ti\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "from transformers import AdamW\n",
    "from tqdm import tqdm\n",
    "import torch\n",
    "# setup GPU/CPU\n",
    "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
    "if torch.cuda.is_available():\n",
    "    print(\"Running on GPU:\", torch.cuda.get_device_name(0))\n",
    "else:\n",
    "    print(\"Running on CPU\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "0fb6c436",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kunuruabhishek/anaconda3/envs/pytorch/lib/python3.7/site-packages/transformers/optimization.py:310: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  FutureWarning,\n",
      "Epoch 0: 100%|██████████| 313/313 [02:27<00:00,  2.13it/s, loss=1.5] \n",
      "Epoch 1: 100%|██████████| 313/313 [02:31<00:00,  2.07it/s, loss=1.13] \n",
      "Epoch 2: 100%|██████████| 313/313 [02:32<00:00,  2.05it/s, loss=0.546]\n"
     ]
    }
   ],
   "source": [
    "model.to(device)\n",
    "model.train()\n",
    "optim = AdamW(model.parameters(), lr=5e-5)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=16, shuffle=True)\n",
    "\n",
    "for epoch in range(3):\n",
    "    model.train()\n",
    "    loop = tqdm(train_loader, leave=True)\n",
    "    for batch in loop:\n",
    "        optim.zero_grad()\n",
    "        input_ids = batch['input_ids'].to(device)\n",
    "        attention_mask = batch['attention_mask'].to(device)\n",
    "        start_positions = batch['start_positions'].to(device)\n",
    "        end_positions = batch['end_positions'].to(device)\n",
    "        outputs = model(input_ids, attention_mask=attention_mask,\n",
    "                        start_positions=start_positions,\n",
    "                        end_positions=end_positions)\n",
    "        loss = outputs[0]\n",
    "        loss.backward()\n",
    "        optim.step()\n",
    "        loop.set_description(f'Epoch {epoch}')\n",
    "        loop.set_postfix(loss=loss.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "f2432589",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4677734375"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "model.eval()\n",
    "val_loader = DataLoader(val_dataset, batch_size=16)\n",
    "acc = []\n",
    "for batch in val_loader:\n",
    "    with torch.no_grad():\n",
    "        input_ids = batch['input_ids'].to(device)\n",
    "        attention_mask = batch['attention_mask'].to(device)\n",
    "        start_true = batch['start_positions'].to(device)\n",
    "        end_true = batch['end_positions'].to(device)\n",
    "        outputs = model(input_ids, attention_mask=attention_mask)\n",
    "        start_pred = torch.argmax(outputs['start_logits'], dim=1)\n",
    "        end_pred = torch.argmax(outputs['end_logits'], dim=1)\n",
    "        acc.append(((start_pred == start_true).sum()/len(start_pred)).item())\n",
    "        acc.append(((end_pred == end_true).sum()/len(end_pred)).item())\n",
    "acc = sum(acc)/len(acc)\n",
    "acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "4afe1099",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "def calculate_f1(pred_start, pred_end, true_start, true_end):\n",
    "    pred_tokens = set(range(pred_start, pred_end + 1))\n",
    "    true_tokens = set(range(true_start, true_end + 1))\n",
    "\n",
    "    common_tokens = pred_tokens.intersection(true_tokens)\n",
    "    if len(common_tokens) == 0:\n",
    "        return 0, 0, 0  # precision, recall, f1\n",
    "\n",
    "    precision = len(common_tokens) / len(pred_tokens)\n",
    "    recall = len(common_tokens) / len(true_tokens)\n",
    "    f1 = 2 * precision * recall / (precision + recall)\n",
    "    return precision, recall, f1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "9b4cb829",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "\n",
    "val_loader = DataLoader(val_dataset, batch_size=16)\n",
    "\n",
    "start_acc = []\n",
    "end_acc = []\n",
    "precisions = []\n",
    "recalls = []\n",
    "f1s = []\n",
    "\n",
    "for batch in val_loader:\n",
    "    with torch.no_grad():\n",
    "        input_ids = batch['input_ids'].to(device)\n",
    "        attention_mask = batch['attention_mask'].to(device)\n",
    "        start_true = batch['start_positions'].to(device)\n",
    "        end_true = batch['end_positions'].to(device)\n",
    "        outputs = model(input_ids, attention_mask=attention_mask)\n",
    "        start_pred = torch.argmax(outputs['start_logits'], dim=1)\n",
    "        end_pred = torch.argmax(outputs['end_logits'], dim=1)\n",
    "        start_acc.append((start_pred == start_true).sum().item() / len(start_pred))\n",
    "        end_acc.append((end_pred == end_true).sum().item() / len(end_pred))\n",
    "        for sp, ep, st, et in zip(start_pred, end_pred, start_true, end_true):\n",
    "            precision, recall, f1 = calculate_f1(sp.item(), ep.item(), st.item(), et.item())\n",
    "            precisions.append(precision)\n",
    "            recalls.append(recall)\n",
    "            f1s.append(f1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "8261f8bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "avg_start_acc = sum(start_acc) / len(start_acc)\n",
    "avg_end_acc = sum(end_acc) / len(end_acc)\n",
    "avg_precision = sum(precisions) / len(precisions)\n",
    "avg_recall = sum(recalls) / len(recalls)\n",
    "avg_f1 = sum(f1s) / len(f1s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "26f3bdec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Start Position Accuracy: 0.4453\n",
      "Average End Position Accuracy: 0.4902\n",
      "Average Precision: 0.5005\n",
      "Average Recall: 0.6066\n",
      "Average F1 Score: 0.4995\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(f\"Average Start Position Accuracy: {avg_start_acc:.4f}\")\n",
    "print(f\"Average End Position Accuracy: {avg_end_acc:.4f}\")\n",
    "print(f\"Average Precision: {avg_precision:.4f}\")\n",
    "print(f\"Average Recall: {avg_recall:.4f}\")\n",
    "print(f\"Average F1 Score: {avg_f1:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79a06522",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58fb106a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad9d3f3e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
